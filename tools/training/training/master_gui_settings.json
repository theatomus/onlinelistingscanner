{
  "cwd": "C:\\Users\\User\\Documents\\4.0alpha\\newBranch1\\tools\\training",
  "items_dir": "C:/Users/User/Documents/4.0alpha/newBranch1/item_contents",
  "backups_root": "C:/Users/User/Documents/4.0alpha/newBranch1/backups/itemcontents",
  "training_dir": "training",
  "server_path": "C:/Users/User/Documents/4.0alpha/newBranch1/llama-b6121-bin-win-cpu-x64/llama-server.exe",
  "model_path": "C:/Users/User/Documents/4.0alpha/newBranch1/models/phi-3-mini-4k-instruct-q4_k_m.gguf",
  "port": 8080,
  "ctx": 2048,
  "threads": 4,
  "ngl": 0,
  "use_web": true,
  "overwrite_corrections": true,
  "instructions_path": "training\\config\\instructions.yaml",
  "ai_enable_llm_spec": true,
  "ai_llm_temp": 0.1,
  "ai_llm_max": 256,
  "val_enable_llm": true,
  "val_enable_web": true,
  "val_llm_temp": 0.1,
  "val_llm_max": 128,
  "sugg_temp": 0.1,
  "sugg_max": 128,
  "web_sources_path": "training\\config\\web_sources.json"
}